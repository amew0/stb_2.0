{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCHzhg9NzOtF"
      },
      "source": [
        "# **Importing Important Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QGA54rw6ZGJL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pathlib \n",
        "import os \n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV2ti6FlyNgo"
      },
      "source": [
        "# **Loading and Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RJHKx5Q31ubO"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path(\"Custom-Dataset\")\n",
        "# print(len(list(data_dir.glob(\"*/*\"))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "OZAKa51slzkX",
        "outputId": "b589f0e5-566f-4031-a116-cdd6450d1cd7"
      },
      "outputs": [],
      "source": [
        "trash = list(data_dir.glob('Can/*'))\n",
        "PIL.Image.open(str(trash[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NX_bMiF56hOK"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "image_height = 224\n",
        "image_width = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnlvnNd9yblJ",
        "outputId": "1bec4d8e-eb9e-4c99-f8f1-435d18c3e7cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21000 files belonging to 3 classes.\n",
            "Using 18900 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.1,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Vp2LKLy8LH",
        "outputId": "d17d47ba-995d-49fe-95c7-b64c929731f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21000 files belonging to 3 classes.\n",
            "Using 2100 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.1,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h_3X5kj4_ch"
      },
      "outputs": [],
      "source": [
        "val_batches = tf.data.experimental.cardinality(val_ds)\n",
        "test_ds = val_ds.take(val_batches // 2)\n",
        "val_ds = val_ds.skip(val_batches // 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jum5DrV05A1o"
      },
      "outputs": [],
      "source": [
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUDx8puuzEJ0"
      },
      "outputs": [],
      "source": [
        "#Classes as inferred\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83MiIL5nzJER"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuU3VoKIzqmr",
        "outputId": "d3803745-25e7-4ab7-b462-2a7a249f4754"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQRrm5zo0F4x"
      },
      "source": [
        "# **Configure Dataset Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vI4zGCvrzw9t"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "# test_ds= test_ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0TQrO_1LDs"
      },
      "source": [
        "# **Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbFeBKqr1OYS"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0MfZ9ewJwe23"
      },
      "source": [
        "## Load The Pre-trained Model - **RESNET50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5nBNxi1xQGI"
      },
      "outputs": [],
      "source": [
        "#importing ResNet50\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "# from tensorflow.keras.applications.vgg16 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLfAiyrj82DT"
      },
      "outputs": [],
      "source": [
        "# Load ResNet50 as the base model\n",
        "def build_model():\n",
        "  base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "\n",
        "  # Freeze the base model's layers\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "      \n",
        "  # Add your own layers on top of the base model\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(image_height, image_width, 3))\n",
        "\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  x = base_model(x, training=False)\n",
        "\n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "  x = layers.Dense(256, activation='relu')(x)\n",
        "  x = layers.Dense(256, activation='relu')(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  num_classes = 3\n",
        "  predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  # Create the final model\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ResNet50 as the base model\n",
        "def build_model():\n",
        "  base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "\n",
        "  # Freeze the base model's layers\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "      \n",
        "  # Add your own layers on top of the base model\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(image_height, image_width, 3))\n",
        "\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  x = base_model(x, training=False)\n",
        "\n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "  x = layers.Dense(256, activation='relu')(x)\n",
        "  x = layers.Dense(256, activation='relu')(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  num_classes = 3\n",
        "  predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  # Create the final model\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.layers.reshaping.flatten.Flatten at 0x7f0b54997d00>"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer_to_remove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model\" was not an Input tensor, it was generated by layer \"input_2\".\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
          ]
        }
      ],
      "source": [
        "# Get a reference to the layer you want to remove\n",
        "layer_to_remove = model.get_layer('flatten')\n",
        "\n",
        "# Create a list to hold the remaining layers\n",
        "remaining_layers = []\n",
        "\n",
        "# Iterate over the layers and exclude the layer to remove\n",
        "for layer in model.layers:\n",
        "    if layer == layer_to_remove:\n",
        "        # Skip the layer you want to remove\n",
        "        continue\n",
        "    # Add the remaining layers to the list\n",
        "    remaining_layers.append(layer)\n",
        "\n",
        "# Define the new model with the remaining layers\n",
        "inputs = model.input\n",
        "outputs = remaining_layers[0](inputs)\n",
        "for layer in remaining_layers[1:]:\n",
        "    outputs = layer(outputs)\n",
        "new_model = tf.keras.models.Model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           multiple             0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 224, 224, 3)  0           ['input_2[1][0]']                \n",
            "                                                                                                  \n",
            " resnet50 (Functional)          (None, 7, 7, 2048)   23587712    ['sequential[1][0]']             \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['resnet50[1][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          524544      ['global_average_pooling2d[1][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          65792       ['dense[1][0]']                  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['dense_1[1][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 3)            771         ['dropout[1][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,178,819\n",
            "Trainable params: 8,224,515\n",
            "Non-trainable params: 15,954,304\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oW56T4OhIa3S"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyg3nqILNFe3",
        "outputId": "ff2357d6-f22c-473c-ff7a-33d17c735af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(\"Models/ResNet50-STBv1.0_10\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.layers[-1].units = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'dense_2',\n",
              " 'trainable': True,\n",
              " 'dtype': 'float32',\n",
              " 'units': 3,\n",
              " 'activation': 'softmax',\n",
              " 'use_bias': True,\n",
              " 'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "  'config': {'seed': None}},\n",
              " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              " 'kernel_regularizer': None,\n",
              " 'bias_regularizer': None,\n",
              " 'activity_regularizer': None,\n",
              " 'kernel_constraint': None,\n",
              " 'bias_constraint': None}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[-1].get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Bn_5u1BLTSq",
        "outputId": "1efbf252-61a8-47d9-9e04-e1cd0b8c94c1"
      },
      "outputs": [],
      "source": [
        "model = build_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kTFELd4xtw8z"
      },
      "outputs": [],
      "source": [
        "for layer in new_model.layers[2].layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJJIwcx4t8ZE",
        "outputId": "870bc809-43c3-4831-ab41-2a288a4790aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'conv3_block1_1_conv',\n",
              " 'trainable': False,\n",
              " 'dtype': 'float32',\n",
              " 'filters': 128,\n",
              " 'kernel_size': (1, 1),\n",
              " 'strides': (2, 2),\n",
              " 'padding': 'valid',\n",
              " 'data_format': 'channels_last',\n",
              " 'dilation_rate': (1, 1),\n",
              " 'groups': 1,\n",
              " 'activation': 'linear',\n",
              " 'use_bias': True,\n",
              " 'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "  'config': {'seed': None}},\n",
              " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              " 'kernel_regularizer': None,\n",
              " 'bias_regularizer': None,\n",
              " 'activity_regularizer': None,\n",
              " 'kernel_constraint': None,\n",
              " 'bias_constraint': None}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[2].layers[39].get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6V5W-R2IN8Km"
      },
      "outputs": [],
      "source": [
        "for layer in new_model.layers[2].layers[7:39]:\n",
        "  layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-gVVelZPvgC",
        "outputId": "3fd391cd-7b7c-48d4-b4c1-a92fab8d7c0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ],
      "source": [
        "# METRICS=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "#             tf.keras.metrics.Precision(name='precision'),\n",
        "#             tf.keras.metrics.Recall(name='recall'),]\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[tf.keras.metrics.Precision()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a function to convert labels to one-hot encoding\n",
        "num_classes = 4\n",
        "def to_one_hot(x, y):\n",
        "    num_classes = 3\n",
        "    y_one_hot = tf.one_hot(y, num_classes)\n",
        "    return x, y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_ds = val_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = test_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAxhQMY1FND3",
        "outputId": "135f1d0e-f45f-4c4b-e862-7f68f9dad81c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1739 - precision: 0.9594\n",
            "Epoch 1: saving model to Tuner/resnet50_stb_v1_0_11.01.h5\n",
            "591/591 [==============================] - 968s 2s/step - loss: 0.1739 - precision: 0.9594 - val_loss: 3.6462 - val_precision: 0.5495\n",
            "Epoch 2/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1722 - precision: 0.9624\n",
            "Epoch 2: saving model to Tuner/resnet50_stb_v1_0_11.02.h5\n",
            "591/591 [==============================] - 942s 2s/step - loss: 0.1722 - precision: 0.9624 - val_loss: 3.1948 - val_precision: 0.5828\n",
            "Epoch 3/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1682 - precision: 0.9627\n",
            "Epoch 3: saving model to Tuner/resnet50_stb_v1_0_11.03.h5\n",
            "591/591 [==============================] - 941s 2s/step - loss: 0.1682 - precision: 0.9627 - val_loss: 3.8633 - val_precision: 0.4722\n",
            "Epoch 4/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1570 - precision: 0.9626\n",
            "Epoch 4: saving model to Tuner/resnet50_stb_v1_0_11.04.h5\n",
            "591/591 [==============================] - 941s 2s/step - loss: 0.1570 - precision: 0.9626 - val_loss: 1.9136 - val_precision: 0.6220\n",
            "Epoch 5/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1736 - precision: 0.9607\n",
            "Epoch 5: saving model to Tuner/resnet50_stb_v1_0_11.05.h5\n",
            "591/591 [==============================] - 941s 2s/step - loss: 0.1736 - precision: 0.9607 - val_loss: 1.5866 - val_precision: 0.6639\n",
            "Epoch 6/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1647 - precision: 0.9660\n",
            "Epoch 6: saving model to Tuner/resnet50_stb_v1_0_11.06.h5\n",
            "591/591 [==============================] - 941s 2s/step - loss: 0.1647 - precision: 0.9660 - val_loss: 1.8258 - val_precision: 0.6158\n",
            "Epoch 7/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1487 - precision: 0.9658\n",
            "Epoch 7: saving model to Tuner/resnet50_stb_v1_0_11.07.h5\n",
            "591/591 [==============================] - 941s 2s/step - loss: 0.1487 - precision: 0.9658 - val_loss: 1.8075 - val_precision: 0.6731\n",
            "Epoch 8/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1569 - precision: 0.9668\n",
            "Epoch 8: saving model to Tuner/resnet50_stb_v1_0_11.08.h5\n",
            "591/591 [==============================] - 941s 2s/step - loss: 0.1569 - precision: 0.9668 - val_loss: 1.5564 - val_precision: 0.6559\n",
            "Epoch 9/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1660 - precision: 0.9642\n",
            "Epoch 9: saving model to Tuner/resnet50_stb_v1_0_11.09.h5\n",
            "591/591 [==============================] - 941s 2s/step - loss: 0.1660 - precision: 0.9642 - val_loss: 2.3604 - val_precision: 0.6265\n",
            "Epoch 10/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1621 - precision: 0.9646\n",
            "Epoch 10: saving model to Tuner/resnet50_stb_v1_0_11.10.h5\n",
            "591/591 [==============================] - 941s 2s/step - loss: 0.1621 - precision: 0.9646 - val_loss: 2.2352 - val_precision: 0.5670\n",
            "Epoch 11/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1533 - precision: 0.9655\n",
            "Epoch 11: saving model to Tuner/resnet50_stb_v1_0_11.11.h5\n",
            "591/591 [==============================] - 940s 2s/step - loss: 0.1533 - precision: 0.9655 - val_loss: 1.9925 - val_precision: 0.6455\n",
            "Epoch 12/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1566 - precision: 0.9656\n",
            "Epoch 12: saving model to Tuner/resnet50_stb_v1_0_11.12.h5\n",
            "591/591 [==============================] - 941s 2s/step - loss: 0.1566 - precision: 0.9656 - val_loss: 1.7783 - val_precision: 0.6593\n",
            "Epoch 13/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1567 - precision: 0.9653\n",
            "Epoch 13: saving model to Tuner/resnet50_stb_v1_0_11.13.h5\n",
            "591/591 [==============================] - 944s 2s/step - loss: 0.1567 - precision: 0.9653 - val_loss: 2.4024 - val_precision: 0.6162\n",
            "Epoch 14/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1622 - precision: 0.9644\n",
            "Epoch 14: saving model to Tuner/resnet50_stb_v1_0_11.14.h5\n",
            "591/591 [==============================] - 942s 2s/step - loss: 0.1622 - precision: 0.9644 - val_loss: 1.5862 - val_precision: 0.6864\n",
            "Epoch 15/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1544 - precision: 0.9674\n",
            "Epoch 15: saving model to Tuner/resnet50_stb_v1_0_11.15.h5\n",
            "591/591 [==============================] - 944s 2s/step - loss: 0.1544 - precision: 0.9674 - val_loss: 2.8825 - val_precision: 0.6185\n",
            "Epoch 16/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1548 - precision: 0.9664\n",
            "Epoch 16: saving model to Tuner/resnet50_stb_v1_0_11.16.h5\n",
            "591/591 [==============================] - 945s 2s/step - loss: 0.1548 - precision: 0.9664 - val_loss: 1.5010 - val_precision: 0.7122\n",
            "Epoch 17/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1657 - precision: 0.9651\n",
            "Epoch 17: saving model to Tuner/resnet50_stb_v1_0_11.17.h5\n",
            "591/591 [==============================] - 946s 2s/step - loss: 0.1657 - precision: 0.9651 - val_loss: 1.9639 - val_precision: 0.6327\n",
            "Epoch 18/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1533 - precision: 0.9680\n",
            "Epoch 18: saving model to Tuner/resnet50_stb_v1_0_11.18.h5\n",
            "591/591 [==============================] - 946s 2s/step - loss: 0.1533 - precision: 0.9680 - val_loss: 1.8663 - val_precision: 0.6537\n",
            "Epoch 19/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1571 - precision: 0.9665\n",
            "Epoch 19: saving model to Tuner/resnet50_stb_v1_0_11.19.h5\n",
            "591/591 [==============================] - 946s 2s/step - loss: 0.1571 - precision: 0.9665 - val_loss: 2.6055 - val_precision: 0.6265\n",
            "Epoch 20/20\n",
            "591/591 [==============================] - ETA: 0s - loss: 0.1494 - precision: 0.9673\n",
            "Epoch 20: saving model to Tuner/resnet50_stb_v1_0_11.20.h5\n",
            "591/591 [==============================] - 946s 2s/step - loss: 0.1494 - precision: 0.9673 - val_loss: 2.0173 - val_precision: 0.5076\n"
          ]
        }
      ],
      "source": [
        "# # Define the checkpoint filepath\n",
        "# checkpoint_filepath = \"/content/drive/MyDrive/Models/ResNet50.h5\"\n",
        "\n",
        "# Create the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath = 'Tuner/resnet50_stb_v1_0_11.{epoch:02d}.h5',\n",
        "    save_weights_only=False,\n",
        "    save_best_only=False,\n",
        "    save_freq='epoch',\n",
        "    verbose=1)\n",
        "\n",
        "# Train the model and save the history and model at each epoch\n",
        "# history = model.fit(train_ds, validation_data=test_ds, epochs=25, verbose=1, callbacks=[checkpoint_callback])\n",
        "history = new_model.fit(\n",
        "    train_ds, \n",
        "validation_data=test_ds,\n",
        "callbacks=[checkpoint_callback],\n",
        "epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'loss': [0.17394830286502838,\n",
              "  0.17223170399665833,\n",
              "  0.16823342442512512,\n",
              "  0.15701289474964142,\n",
              "  0.1735851913690567,\n",
              "  0.16469287872314453,\n",
              "  0.14872506260871887,\n",
              "  0.15694721043109894,\n",
              "  0.1660156100988388,\n",
              "  0.16205072402954102,\n",
              "  0.15328726172447205,\n",
              "  0.15662208199501038,\n",
              "  0.15667012333869934,\n",
              "  0.16219227015972137,\n",
              "  0.15438377857208252,\n",
              "  0.15475082397460938,\n",
              "  0.16571283340454102,\n",
              "  0.15332841873168945,\n",
              "  0.15714170038700104,\n",
              "  0.14944279193878174],\n",
              " 'precision': [0.9594164490699768,\n",
              "  0.9623738527297974,\n",
              "  0.9627302289009094,\n",
              "  0.962637722492218,\n",
              "  0.9607051014900208,\n",
              "  0.9660080075263977,\n",
              "  0.9658185243606567,\n",
              "  0.9667741656303406,\n",
              "  0.964242696762085,\n",
              "  0.9645916223526001,\n",
              "  0.9655285477638245,\n",
              "  0.9656357169151306,\n",
              "  0.9652572870254517,\n",
              "  0.9644439816474915,\n",
              "  0.9674144387245178,\n",
              "  0.9664223790168762,\n",
              "  0.9651143550872803,\n",
              "  0.9679697751998901,\n",
              "  0.9664536118507385,\n",
              "  0.9672578573226929],\n",
              " 'val_loss': [3.6461703777313232,\n",
              "  3.1948273181915283,\n",
              "  3.863295316696167,\n",
              "  1.9136126041412354,\n",
              "  1.5865730047225952,\n",
              "  1.8257778882980347,\n",
              "  1.8074617385864258,\n",
              "  1.5563933849334717,\n",
              "  2.3604207038879395,\n",
              "  2.2351889610290527,\n",
              "  1.992501139640808,\n",
              "  1.778285264968872,\n",
              "  2.40240478515625,\n",
              "  1.5862401723861694,\n",
              "  2.8824870586395264,\n",
              "  1.5009888410568237,\n",
              "  1.963879108428955,\n",
              "  1.8662605285644531,\n",
              "  2.6055350303649902,\n",
              "  2.017305850982666],\n",
              " 'val_precision': [0.5494672656059265,\n",
              "  0.5828220844268799,\n",
              "  0.4722222089767456,\n",
              "  0.6220472455024719,\n",
              "  0.6638513803482056,\n",
              "  0.6157556176185608,\n",
              "  0.6730769276618958,\n",
              "  0.6559485793113708,\n",
              "  0.6265432238578796,\n",
              "  0.5670436024665833,\n",
              "  0.6455108523368835,\n",
              "  0.6593406796455383,\n",
              "  0.6162246465682983,\n",
              "  0.6863999962806702,\n",
              "  0.6185243129730225,\n",
              "  0.712195098400116,\n",
              "  0.6326860785484314,\n",
              "  0.6537266969680786,\n",
              "  0.6265060305595398,\n",
              "  0.507563054561615]}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjCZDwKAoSvQ"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "RL37zMKcoRw3",
        "outputId": "a7009340-7c9e-4b2c-9263-2bfb1e2869d2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# acc = history.history['accuracy']\n",
        "# val_acc = history.history['val_accuracy']\n",
        "\n",
        "acc = history.history['precision']\n",
        "val_acc = history.history['val_precision']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training precision')\n",
        "plt.plot(val_acc, label='Validation precision')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation precision')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RGAVvGmoyNO",
        "outputId": "82247af3-4c24-4a97-c343-80959db5ff0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ResNet50-STBv1.0_10/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ResNet50-STBv1.0_10/assets\n"
          ]
        }
      ],
      "source": [
        "# model.save(\"Models/ResNet50-STBv1.0_8\")\n",
        "new_model.save(\"Models/ResNet50-STBv1.0_10\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F13sHLil2Hi5",
        "outputId": "1ae29e56-bb00-42c0-f1db-b9324b09d78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model\" was not an Input tensor, it was generated by layer \"input_2\".\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model\" was not an Input tensor, it was generated by layer \"input_2\".\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
          ]
        }
      ],
      "source": [
        "# Load the best model (u should have saved it from the checkpoints above)\n",
        "# model_ = tf.keras.models.load_model(\"/content/drive/MyDrive/Tuner/resnet50_stb_v1_0_6.08.h5\")  \n",
        "model_ = tf.keras.models.load_model(\"Tuner/resnet50_stb_v1_0_11.16.h5\")  \n",
        "# /home/ai-05/Desktop/sdp/Tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5I3VaA8bSlu",
        "outputId": "aacaed9c-5e21-4922-9b92-910e89031eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/resnet50_stb_v1_0_11/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/resnet50_stb_v1_0_11/assets\n"
          ]
        }
      ],
      "source": [
        "# model_.save(\"/content/drive/My Drive/Models/ResNet50-STBv1.0_6\")\n",
        "model_.save(\"Models/resnet50_stb_v1_0_11\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feqwWGoSmvbD"
      },
      "source": [
        "## Evaluation and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsI3TeIrm3YM",
        "outputId": "812555b5-49ca-421c-adfe-38ddb5673d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 699 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Evaluating on a new dataset from the internet\n",
        "# paper and plastic from  https://www.kaggle.com/datasets/arthurcen/waste-images-from-sushi-restaurant\n",
        "# can from https://universe.roboflow.com/dataset-t7hz7/cans-fdboa/dataset/1\n",
        "test_dir = pathlib.Path(\"Dataset-testing (from internet)\")\n",
        "# test_dir = pathlib.Path(\"WasteImagesDataset\")\n",
        "\n",
        "batch_size = 32\n",
        "image_height = 224\n",
        "image_width = 224\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"Models/ResNet50-STBv1.0_6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFUefrUhm7qd",
        "outputId": "07b66ae6-a5e6-4e95-f065-c84415e3912e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82/82 [==============================] - 102s 1s/step - loss: 0.5662 - accuracy: 0.7990\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5661628842353821, 0.7990007400512695]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_ds)\n",
        "# print('Test accuracy :', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUajWQvrsE5f"
      },
      "outputs": [],
      "source": [
        "num_trials = 15\n",
        "from kerastuner import HyperParameters\n",
        "tuner_hps_summary = tuner.get_best_hyperparameters(num_trials=num_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN8BYWee5vhr",
        "outputId": "57df625c-ae8a-4b14-a62e-94f32b89b151"
      },
      "outputs": [],
      "source": [
        "summary_dict = {}\n",
        "for i,a in enumerate(tuner_hps_summary):\n",
        "  print(f\"Best trial {i}:\")\n",
        "\n",
        "  trial_dict = {}\n",
        "  for hp_name, hp_value in a.values.items():\n",
        "      # print(f\"{hp_value}\")\n",
        "      trial_dict[hp_name] = hp_value\n",
        "  summary_dict[i] = trial_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOBMQpwy5DMP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a pandas DataFrame from the dictionary\n",
        "df = pd.DataFrame.from_dict(summary_dict, orient='index')\n",
        "\n",
        "# Write the DataFrame to an excel file\n",
        "df.to_excel('/content/drive/My Drive/Models/output-3_1.xlsx', na_rep='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQM_57QYsx0e"
      },
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters:\")\n",
        "\n",
        "for i,trial in enumerate(tuner_hps_summary):\n",
        "  print(f\"Trial {i}\")\n",
        "  for hp_name, hp_value in trial.values.items():\n",
        "      print(f\"- {hp_name}: {hp_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIv36xGLUZOK"
      },
      "source": [
        "## Convert to TfLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdZquiRGUgVB",
        "outputId": "e44056c1-7f17-49ea-c11c-cd177f2dc51b"
      },
      "outputs": [],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('/content/drive/My Drive/Models/ResNet50-STBv1.0_6_Lite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaTZcGrqbssG",
        "outputId": "263f3a68-f71e-41e5-a098-f6ba3279d731"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
