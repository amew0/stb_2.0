{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCHzhg9NzOtF"
      },
      "source": [
        "# **Importing Important Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QGA54rw6ZGJL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pathlib \n",
        "import os \n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV2ti6FlyNgo"
      },
      "source": [
        "# **Loading and Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RJHKx5Q31ubO"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path(\"Custom-Dataset-4\")\n",
        "# print(len(list(data_dir.glob(\"*/*\"))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "OZAKa51slzkX",
        "outputId": "b589f0e5-566f-4031-a116-cdd6450d1cd7"
      },
      "outputs": [],
      "source": [
        "trash = list(data_dir.glob('Can/*'))\n",
        "PIL.Image.open(str(trash[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NX_bMiF56hOK"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "image_height = 224\n",
        "image_width = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnlvnNd9yblJ",
        "outputId": "1bec4d8e-eb9e-4c99-f8f1-435d18c3e7cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22543 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  # validation_split=0.1,\n",
        "  # subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Vp2LKLy8LH",
        "outputId": "d17d47ba-995d-49fe-95c7-b64c929731f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21000 files belonging to 3 classes.\n",
            "Using 2100 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.1,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h_3X5kj4_ch"
      },
      "outputs": [],
      "source": [
        "val_batches = tf.data.experimental.cardinality(val_ds)\n",
        "test_ds = val_ds.take(val_batches // 2)\n",
        "val_ds = val_ds.skip(val_batches // 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jum5DrV05A1o"
      },
      "outputs": [],
      "source": [
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AUDx8puuzEJ0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Can', 'General', 'Paper', 'Plastic']\n"
          ]
        }
      ],
      "source": [
        "#Classes as inferred\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83MiIL5nzJER"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuU3VoKIzqmr",
        "outputId": "d3803745-25e7-4ab7-b462-2a7a249f4754"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQRrm5zo0F4x"
      },
      "source": [
        "# **Configure Dataset Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vI4zGCvrzw9t"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "# val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "# test_ds= test_ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0TQrO_1LDs"
      },
      "source": [
        "# **Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mbFeBKqr1OYS"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0MfZ9ewJwe23"
      },
      "source": [
        "## Load The Pre-trained Model - **RESNET50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oW56T4OhIa3S"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.utils.disable_interactive_logging()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyg3nqILNFe3",
        "outputId": "ff2357d6-f22c-473c-ff7a-33d17c735af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(\"Models/ResNet50-STBv1.0_10\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-gVVelZPvgC",
        "outputId": "3fd391cd-7b7c-48d4-b4c1-a92fab8d7c0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[tf.keras.metrics.Precision()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a function to convert labels to one-hot encoding\n",
        "num_classes = 4\n",
        "def to_one_hot(x, y):\n",
        "    num_classes = 3\n",
        "    y_one_hot = tf.one_hot(y, num_classes)\n",
        "    return x, y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_ds = val_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = test_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAxhQMY1FND3",
        "outputId": "135f1d0e-f45f-4c4b-e862-7f68f9dad81c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "705/705 [==============================] - ETA: 0s - loss: 52413.3906 - precision_1: 0.2752\n",
            "Epoch 1: saving model to Tuner/ResNet50-STBv1.1/01.h5\n",
            "705/705 [==============================] - 2127s 3s/step - loss: 52413.3906 - precision_1: 0.2752 - val_loss: 1297798.6250 - val_precision_1: 0.2576\n",
            "Epoch 2/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.2707\n",
            "Epoch 2: saving model to Tuner/ResNet50-STBv1.1/02.h5\n",
            "705/705 [==============================] - 2119s 3s/step - loss: nan - precision_1: 0.2707 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 3/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 3: saving model to Tuner/ResNet50-STBv1.1/03.h5\n",
            "705/705 [==============================] - 2046s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 4/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 4: saving model to Tuner/ResNet50-STBv1.1/04.h5\n",
            "705/705 [==============================] - 2021s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 5/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 5: saving model to Tuner/ResNet50-STBv1.1/05.h5\n",
            "705/705 [==============================] - 2022s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 6/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 6: saving model to Tuner/ResNet50-STBv1.1/06.h5\n",
            "705/705 [==============================] - 2079s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 7/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 7: saving model to Tuner/ResNet50-STBv1.1/07.h5\n",
            "705/705 [==============================] - 2105s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 8/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 8: saving model to Tuner/ResNet50-STBv1.1/08.h5\n",
            "705/705 [==============================] - 2074s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 9/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 9: saving model to Tuner/ResNet50-STBv1.1/09.h5\n",
            "705/705 [==============================] - 2044s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 10/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 10: saving model to Tuner/ResNet50-STBv1.1/10.h5\n",
            "705/705 [==============================] - 2060s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 11/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 11: saving model to Tuner/ResNet50-STBv1.1/11.h5\n",
            "705/705 [==============================] - 2078s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 12/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 12: saving model to Tuner/ResNet50-STBv1.1/12.h5\n",
            "705/705 [==============================] - 2099s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 13/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 13: saving model to Tuner/ResNet50-STBv1.1/13.h5\n",
            "705/705 [==============================] - 2101s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 14/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 14: saving model to Tuner/ResNet50-STBv1.1/14.h5\n",
            "705/705 [==============================] - 2007s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 15/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 15: saving model to Tuner/ResNet50-STBv1.1/15.h5\n",
            "705/705 [==============================] - 1968s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 16/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 16: saving model to Tuner/ResNet50-STBv1.1/16.h5\n",
            "705/705 [==============================] - 2039s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 17/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 17: saving model to Tuner/ResNet50-STBv1.1/17.h5\n",
            "705/705 [==============================] - 2077s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 18/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 18: saving model to Tuner/ResNet50-STBv1.1/18.h5\n",
            "705/705 [==============================] - 2070s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 19/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 19: saving model to Tuner/ResNet50-STBv1.1/19.h5\n",
            "705/705 [==============================] - 2044s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 20/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 20: saving model to Tuner/ResNet50-STBv1.1/20.h5\n",
            "705/705 [==============================] - 2020s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 21/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 21: saving model to Tuner/ResNet50-STBv1.1/21.h5\n",
            "705/705 [==============================] - 2054s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 22/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 22: saving model to Tuner/ResNet50-STBv1.1/22.h5\n",
            "705/705 [==============================] - 2020s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 23/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 23: saving model to Tuner/ResNet50-STBv1.1/23.h5\n",
            "705/705 [==============================] - 2085s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 24/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 24: saving model to Tuner/ResNet50-STBv1.1/24.h5\n",
            "705/705 [==============================] - 2066s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n",
            "Epoch 25/25\n",
            "705/705 [==============================] - ETA: 0s - loss: nan - precision_1: 0.0000e+00\n",
            "Epoch 25: saving model to Tuner/ResNet50-STBv1.1/25.h5\n",
            "705/705 [==============================] - 2080s 3s/step - loss: nan - precision_1: 0.0000e+00 - val_loss: nan - val_precision_1: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "# # Define the checkpoint filepath\n",
        "# checkpoint_filepath = \"/content/drive/MyDrive/Models/ResNet50.h5\"\n",
        "\n",
        "# Create the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath = 'Tuner/ResNet50-STBv1.1/{epoch:02d}.h5',\n",
        "    save_weights_only=False,\n",
        "    save_best_only=False,\n",
        "    save_freq='epoch',\n",
        "    verbose=1)\n",
        "\n",
        "# Train the model and save the history and model at each epoch\n",
        "# history = model.fit(train_ds, validation_data=test_ds, epochs=25, verbose=1, callbacks=[checkpoint_callback])\n",
        "history = model.fit(\n",
        "    train_ds, \n",
        "validation_data=test_ds,\n",
        "callbacks=[checkpoint_callback],\n",
        "epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'loss': [52413.390625,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan],\n",
              " 'precision_1': [0.27518871426582336,\n",
              "  0.27070313692092896,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0],\n",
              " 'val_loss': [1297798.625,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan,\n",
              "  nan],\n",
              " 'val_precision_1': [0.2575962245464325,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0]}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjCZDwKAoSvQ"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "RL37zMKcoRw3",
        "outputId": "a7009340-7c9e-4b2c-9263-2bfb1e2869d2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# acc = history.history['accuracy']\n",
        "# val_acc = history.history['val_accuracy']\n",
        "\n",
        "acc = history.history['precision_1']\n",
        "val_acc = history.history['val_precision_1']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training precision')\n",
        "plt.plot(val_acc, label='Validation precision')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation precision')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RGAVvGmoyNO",
        "outputId": "82247af3-4c24-4a97-c343-80959db5ff0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ResNet-4-50-STBv1.0/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ResNet-4-50-STBv1.0/assets\n"
          ]
        }
      ],
      "source": [
        "# model.save(\"Models/ResNet50-STBv1.0_8\")\n",
        "model.save(\"Models/ResNet-4-50-STBv1.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F13sHLil2Hi5",
        "outputId": "1ae29e56-bb00-42c0-f1db-b9324b09d78e"
      },
      "outputs": [],
      "source": [
        "# Load the best model (u should have saved it from the checkpoints above)\n",
        "# model_ = tf.keras.models.load_model(\"/content/drive/MyDrive/Tuner/resnet50_stb_v1_0_6.08.h5\")  \n",
        "model_ = tf.keras.models.load_model(\"Tuner/resnet50_stb_v1_0_11.16.h5\")  \n",
        "# /home/ai-05/Desktop/sdp/Tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5I3VaA8bSlu",
        "outputId": "aacaed9c-5e21-4922-9b92-910e89031eac"
      },
      "outputs": [],
      "source": [
        "# model_.save(\"/content/drive/My Drive/Models/ResNet50-STBv1.0_6\")\n",
        "model_.save(\"Models/resnet50_stb_v1_0_11\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feqwWGoSmvbD"
      },
      "source": [
        "## Evaluation and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsI3TeIrm3YM",
        "outputId": "812555b5-49ca-421c-adfe-38ddb5673d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2962 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Evaluating on a new dataset from the internet\n",
        "# paper and plastic from  https://www.kaggle.com/datasets/arthurcen/waste-images-from-sushi-restaurant\n",
        "# can from https://universe.roboflow.com/dataset-t7hz7/cans-fdboa/dataset/1\n",
        "# test_dir = pathlib.Path(\"Dataset-testing (from internet)\")\n",
        "test_dir = pathlib.Path(\"WasteImagesDataset-4\")\n",
        "\n",
        "batch_size = 32\n",
        "image_height = 224\n",
        "image_width = 224\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"Models/ResNet50-STBv1.0_6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFUefrUhm7qd",
        "outputId": "07b66ae6-a5e6-4e95-f065-c84415e3912e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/82 [==>...........................] - ETA: 1:28 - loss: 0.5281 - accuracy: 0.7906"
          ]
        }
      ],
      "source": [
        "model.evaluate(test_ds)\n",
        "# print('Test accuracy :', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUajWQvrsE5f"
      },
      "outputs": [],
      "source": [
        "num_trials = 15\n",
        "from kerastuner import HyperParameters\n",
        "tuner_hps_summary = tuner.get_best_hyperparameters(num_trials=num_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN8BYWee5vhr",
        "outputId": "57df625c-ae8a-4b14-a62e-94f32b89b151"
      },
      "outputs": [],
      "source": [
        "summary_dict = {}\n",
        "for i,a in enumerate(tuner_hps_summary):\n",
        "  print(f\"Best trial {i}:\")\n",
        "\n",
        "  trial_dict = {}\n",
        "  for hp_name, hp_value in a.values.items():\n",
        "      # print(f\"{hp_value}\")\n",
        "      trial_dict[hp_name] = hp_value\n",
        "  summary_dict[i] = trial_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOBMQpwy5DMP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a pandas DataFrame from the dictionary\n",
        "df = pd.DataFrame.from_dict(summary_dict, orient='index')\n",
        "\n",
        "# Write the DataFrame to an excel file\n",
        "df.to_excel('/content/drive/My Drive/Models/output-3_1.xlsx', na_rep='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQM_57QYsx0e"
      },
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters:\")\n",
        "\n",
        "for i,trial in enumerate(tuner_hps_summary):\n",
        "  print(f\"Trial {i}\")\n",
        "  for hp_name, hp_value in trial.values.items():\n",
        "      print(f\"- {hp_name}: {hp_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIv36xGLUZOK"
      },
      "source": [
        "## Convert to TfLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdZquiRGUgVB",
        "outputId": "e44056c1-7f17-49ea-c11c-cd177f2dc51b"
      },
      "outputs": [],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('/content/drive/My Drive/Models/ResNet50-STBv1.0_6_Lite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaTZcGrqbssG",
        "outputId": "263f3a68-f71e-41e5-a098-f6ba3279d731"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
