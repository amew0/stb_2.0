{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SCHzhg9NzOtF"
      },
      "source": [
        "# **Importing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ai-05/Desktop/sdp\n"
          ]
        }
      ],
      "source": [
        "%cd /home/ai-05/Desktop/sdp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QGA54rw6ZGJL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-20 11:32:25.603939: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-04-20 11:32:25.635879: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-20 11:32:26.082236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pathlib\n",
        "import random\n",
        "from datetime import datetime\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras_tuner import Hyperband, Objective, BayesianOptimization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-20 11:32:32.943362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-20 11:32:32.960634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-20 11:32:32.960779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
          ]
        }
      ],
      "source": [
        "gpu = tf.config.list_physical_devices('GPU')\n",
        "print(gpu)\n",
        "if gpu:\n",
        "    tf.config.experimental.set_virtual_device_configuration(gpu[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "NEWMODELNAME = \"InceptionV3-STBv1.6\"\n",
        "# BASEMODELNAME = \"InceptionV3-STBv1.0\"\n",
        "BASEMODELNAME = \"ResNet50-STBv1.0_18\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ds_generator(path, batch_size=16, to_1_hot=False, shuffle=True, image_height=224, image_width=224, seed=123, num_classes=3):\n",
        "    dir = pathlib.Path(path)\n",
        "\n",
        "\n",
        "    ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        dir,\n",
        "        seed=seed,\n",
        "        image_size=(image_height, image_width),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle)\n",
        "    \n",
        "    if to_1_hot:\n",
        "        # Create a function to convert labels to one-hot encoding\n",
        "        num_classes = num_classes\n",
        "        def to_one_hot(x, y):\n",
        "            num_classes = 3\n",
        "            y_one_hot = tf.one_hot(y, num_classes)\n",
        "            return x, y_one_hot\n",
        "        ds = ds.map(to_one_hot)\n",
        "    \n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 63306 files belonging to 3 classes.\n",
            "Found 167 files belonging to 3 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-20 11:33:11.758440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-20 11:33:11.758618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-20 11:33:11.758690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-20 11:33:12.167477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-20 11:33:12.167621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-20 11:33:12.167696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-20 11:33:12.167768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5000 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "train_ds = ds_generator(\"/home/ai-05/Desktop/sdp/dataset\", 16, True)\n",
        "test_ds = ds_generator(\"/home/ai-05/Desktop/sdp/dcrpi-167\", 16,True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Prep**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_layer_index = {\n",
        "    0: [1,8,'conv2d_94-96'],\n",
        "    1: [8,30,'conv2d_96-103'],\n",
        "    2: [30,55,'conv2d_104-112'],\n",
        "    3: [55,87,'conv2d_112-119'],\n",
        "    4: [87,-1,'conv2d_120-187']\n",
        "    # 5: [51,61,'conv3_block2'],\n",
        "    # 6: [61,71,'conv3_block3'],\n",
        "    # 7: [71,81,'conv3_block4'],\n",
        "    # 8: [81,93,'conv4_block1'],\n",
        "    # 9: [93,103,'conv4_block2'],\n",
        "    # 10: [103,113,'conv4_block3'],\n",
        "    # 11: [113,123,'conv4_block4'],\n",
        "    # 12: [123, 133,'conv4_block5'],\n",
        "    # 13: [133,143,'conv4_block6'],\n",
        "    # 14: [143,155,'conv5_block1'],\n",
        "    # 15: [155,165,'conv5_block2'],\n",
        "    # 16: [165, -1,'conv5_block3']\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: [1, 8, 'conv2d_94-96'], 1: [8, 30, 'conv2d_96-103'], 2: [30, 55, 'conv2d_104-112'], 3: [55, 87, 'conv2d_112-119'], 4: [87, -1, 'conv2d_120-187']}\n"
          ]
        }
      ],
      "source": [
        "print(block_layer_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "img_size = (224,224) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = tf.keras.models.load_model(f\"/home/ai-05/Desktop/sdp/Models/{BASEMODELNAME}\")\n",
        "# base_model = InceptionV3(input_shape=img_size + (3,),\n",
        "#                          weights='imagenet',\n",
        "#                          include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 224, 224, 3)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_model.input_shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Tuner**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner_path = f'Tuner/{BASEMODELNAME}'\n",
        "num_trials = 30\n",
        "tunable_indices = [0,1,2,3,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_trials(tuner_path, num_trials, tunable_indices):\n",
        "    \"\"\"\n",
        "        'Args': \n",
        "            tuner_path: str something similiar to 'Tuner/ResNet50-STBv1.0_15'\n",
        "            num_trials: int (count them)\n",
        "            tunable_indices: list(int) to tune them\n",
        "        'Returns':\n",
        "            a dict of dict in a panda DataFrame\n",
        "            cols: the trials 0 1 2 ...\n",
        "            rows: the name of the hps\n",
        "\n",
        "    \"\"\"\n",
        "    hps_trials = {}\n",
        "    for i in range(num_trials):\n",
        "        trial_dir = f\"{tuner_path}/HB_tuner/trial_00{i:02d}/\"\n",
        "        if not os.path.exists(trial_dir):\n",
        "            os.makedirs(trial_dir)\n",
        "        f = open(f\"{tuner_path}/HB_tuner/trial_00{i:02d}/trial.json\", 'r')\n",
        "        hps_trial = json.load(f)\n",
        "        hps_trials[i] = hps_trial['hyperparameters']['values']\n",
        "        \n",
        "    d = pd.DataFrame(hps_trials)\n",
        "    d = d.fillna(-1)\n",
        "    for i in range(len(d.columns)): d[i] = d[i].astype(int)\n",
        "\n",
        "    name = lambda i: block_layer_index[i][2]\n",
        "    # in tunable_indices and already in hps_trials\n",
        "    names = [name(t) for t in tunable_indices if name(t) in d.index] \n",
        "    d.T[names].T\n",
        "\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comp(hps, d_i):\n",
        "    # compares two dicts if they are equal \n",
        "    for k in hps:\n",
        "        if k not in d_i.index or  hps[k] != d_i[k]: return False\n",
        "        else: continue\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Tuner/InceptionV3-STBv1.0'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tuner_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(hp, retrieve_trial=True):\n",
        "    \n",
        "    # resnet_base = model.layers[2]\n",
        "    # resnet_base.trainable = False\n",
        "    print(model.input_shape)\n",
        "    name = lambda i: block_layer_index[i][2]\n",
        "    names = list(map(name, tunable_indices))\n",
        "\n",
        "    hps = {}\n",
        "    for i,name_ in enumerate(names):\n",
        "        hps[name_] = hp.Choice(name_, [True,False]) == True\n",
        "    if retrieve_trial:\n",
        "        d = retrieve_trials( tuner_path, num_trials, tunable_indices)\n",
        "        exists = True\n",
        "        while exists:\n",
        "            checks = []\n",
        "            for i in range(len(d.columns)):\n",
        "                equal = comp(hps,d[i])\n",
        "                checks.append(equal)\n",
        "                if equal: break\n",
        "            checks = np.array(checks)\n",
        "            exists = np.any(checks) # If there is any True value returns True\n",
        "            \n",
        "            if exists:\n",
        "                print(f\"HP combination already exists with the following values:{hps}\")\n",
        "            else:print(f\"HP combination is new.\\n{hps}\")\n",
        "                \n",
        "            # Flip the value of the boolean at the chosen key\n",
        "            flip_key = random.choice(tunable_indices)\n",
        "            flip_key = name(flip_key)\n",
        "            hps[flip_key] = not hps[flip_key]\n",
        "\n",
        "    for bli_k, bli_v in block_layer_index.items():\n",
        "        print(bli_k)\n",
        "        if bli_k in tunable_indices:\n",
        "            for layer in base_model.layers[bli_v[0]:bli_v[1]]:\n",
        "                layer.trainable = hps[name(bli_k)]\n",
        "        \n",
        "    base_model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[tf.metrics.Recall()])\n",
        "    return base_model\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "# Define the hyperparameters\n",
        "hp = HyperParameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "new_model = build_model(hp, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Inputs to a layer should be tensors. Got '<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7f4c29ab6f50>' (of type <class 'keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters'>) as input for layer 'model_1'.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner \u001b[39m=\u001b[39m Hyperband(\n\u001b[1;32m      2\u001b[0m     new_model,\n\u001b[1;32m      3\u001b[0m     objective\u001b[39m=\u001b[39;49mObjective(\u001b[39m'\u001b[39;49m\u001b[39mval_recall\u001b[39;49m\u001b[39m'\u001b[39;49m, direction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      4\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     factor\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      7\u001b[0m     directory\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTuner/\u001b[39;49m\u001b[39m{\u001b[39;49;00mNEWMODELNAME\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     project_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mHB_tuner\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/tuners/hyperband.py:418\u001b[0m, in \u001b[0;36mHyperband.__init__\u001b[0;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    392\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    393\u001b[0m     hypermodel\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    405\u001b[0m ):\n\u001b[1;32m    406\u001b[0m     oracle \u001b[39m=\u001b[39m HyperbandOracle(\n\u001b[1;32m    407\u001b[0m         objective,\n\u001b[1;32m    408\u001b[0m         max_epochs\u001b[39m=\u001b[39mmax_epochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m         max_consecutive_failed_trials\u001b[39m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[1;32m    417\u001b[0m     )\n\u001b[0;32m--> 418\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(oracle\u001b[39m=\u001b[39;49moracle, hypermodel\u001b[39m=\u001b[39;49mhypermodel, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:113\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m hypermodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mrun_trial \u001b[39mis\u001b[39;00m Tuner\u001b[39m.\u001b[39mrun_trial:\n\u001b[1;32m    106\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`hypermodel` if the user defines the search space in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing a `HyperModel` instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n\u001b[0;32m--> 113\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    114\u001b[0m     oracle\u001b[39m=\u001b[39;49moracle,\n\u001b[1;32m    115\u001b[0m     hypermodel\u001b[39m=\u001b[39;49mhypermodel,\n\u001b[1;32m    116\u001b[0m     directory\u001b[39m=\u001b[39;49mdirectory,\n\u001b[1;32m    117\u001b[0m     project_name\u001b[39m=\u001b[39;49mproject_name,\n\u001b[1;32m    118\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[1;32m    119\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m    120\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_model_size \u001b[39m=\u001b[39m max_model_size\n\u001b[1;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:133\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreload()\n\u001b[1;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     \u001b[39m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_populate_initial_space()\n\u001b[1;32m    135\u001b[0m \u001b[39m# Run in distributed mode.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m dist_utils\u001b[39m.\u001b[39mis_chief_oracle():\n\u001b[1;32m    137\u001b[0m     \u001b[39m# Blocks forever.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[39m# Avoid import at the top, to avoid inconsistent protobuf versions.\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:204\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mdeclare_hyperparameters(hp)\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[0;32m--> 204\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_activate_all_conditions()\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:161\u001b[0m, in \u001b[0;36mBaseTuner._activate_all_conditions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m hp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_space()\n\u001b[1;32m    160\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbuild(hp)\n\u001b[1;32m    162\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Update the recorded scopes.\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras/engine/input_spec.py:213\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m inputs:\n\u001b[1;32m    208\u001b[0m     \u001b[39m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[39m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs to a layer should be tensors. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m}\u001b[39;00m\u001b[39m) as input for layer \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[1;32m    219\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    220\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n",
            "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got '<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7f4c29ab6f50>' (of type <class 'keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters'>) as input for layer 'model_1'."
          ]
        }
      ],
      "source": [
        "tuner = Hyperband(\n",
        "    new_model,\n",
        "    objective=Objective('val_recall', direction='max'),\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    overwrite=True,\n",
        "    directory=f'Tuner/{NEWMODELNAME}',\n",
        "    project_name='HB_tuner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install keras-tuner[bayesian]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ai-05/Desktop/sdp/Tuner/InceptionV3-STBv1.0'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tuner_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Inputs to a layer should be tensors. Got '<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7fa0734d3580>' (of type <class 'keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters'>) as input for layer 'model_1'.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner \u001b[39m=\u001b[39m BayesianOptimization(\n\u001b[1;32m      2\u001b[0m     hypermodel\u001b[39m=\u001b[39;49mnew_model,\n\u001b[1;32m      3\u001b[0m     objective\u001b[39m=\u001b[39;49mObjective(\u001b[39m'\u001b[39;49m\u001b[39mval_recall\u001b[39;49m\u001b[39m'\u001b[39;49m, direction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      4\u001b[0m     max_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39m123\u001b[39;49m\n\u001b[1;32m      6\u001b[0m )\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/tuners/bayesian.py:393\u001b[0m, in \u001b[0;36mBayesianOptimization.__init__\u001b[0;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    366\u001b[0m     hypermodel\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    379\u001b[0m ):\n\u001b[1;32m    380\u001b[0m     oracle \u001b[39m=\u001b[39m BayesianOptimizationOracle(\n\u001b[1;32m    381\u001b[0m         objective\u001b[39m=\u001b[39mobjective,\n\u001b[1;32m    382\u001b[0m         max_trials\u001b[39m=\u001b[39mmax_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m         max_consecutive_failed_trials\u001b[39m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[1;32m    392\u001b[0m     )\n\u001b[0;32m--> 393\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(oracle\u001b[39m=\u001b[39;49moracle, hypermodel\u001b[39m=\u001b[39;49mhypermodel, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:113\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m hypermodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mrun_trial \u001b[39mis\u001b[39;00m Tuner\u001b[39m.\u001b[39mrun_trial:\n\u001b[1;32m    106\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`hypermodel` if the user defines the search space in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing a `HyperModel` instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n\u001b[0;32m--> 113\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    114\u001b[0m     oracle\u001b[39m=\u001b[39;49moracle,\n\u001b[1;32m    115\u001b[0m     hypermodel\u001b[39m=\u001b[39;49mhypermodel,\n\u001b[1;32m    116\u001b[0m     directory\u001b[39m=\u001b[39;49mdirectory,\n\u001b[1;32m    117\u001b[0m     project_name\u001b[39m=\u001b[39;49mproject_name,\n\u001b[1;32m    118\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[1;32m    119\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m    120\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_model_size \u001b[39m=\u001b[39m max_model_size\n\u001b[1;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:133\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreload()\n\u001b[1;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     \u001b[39m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_populate_initial_space()\n\u001b[1;32m    135\u001b[0m \u001b[39m# Run in distributed mode.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m dist_utils\u001b[39m.\u001b[39mis_chief_oracle():\n\u001b[1;32m    137\u001b[0m     \u001b[39m# Blocks forever.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[39m# Avoid import at the top, to avoid inconsistent protobuf versions.\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:204\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mdeclare_hyperparameters(hp)\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[0;32m--> 204\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_activate_all_conditions()\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:161\u001b[0m, in \u001b[0;36mBaseTuner._activate_all_conditions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m hp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_space()\n\u001b[1;32m    160\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbuild(hp)\n\u001b[1;32m    162\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Update the recorded scopes.\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/Desktop/sdp/cpuonly/lib/python3.10/site-packages/keras/engine/input_spec.py:213\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m inputs:\n\u001b[1;32m    208\u001b[0m     \u001b[39m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[39m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs to a layer should be tensors. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m}\u001b[39;00m\u001b[39m) as input for layer \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[1;32m    219\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    220\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n",
            "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got '<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7fa0734d3580>' (of type <class 'keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters'>) as input for layer 'model_1'."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "tuner = BayesianOptimization(\n",
        "    hypermodel=new_model,\n",
        "    objective=Objective('val_recall', direction='max'),\n",
        "    max_trials=50,\n",
        "    seed=123\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tuner' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner\u001b[39m.\u001b[39msearch_space_summary(extended\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tuner' is not defined"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary(extended=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InceptionV3-STBv1.6\n"
          ]
        }
      ],
      "source": [
        "log_dir = f\"logs/{NEWMODELNAME}\"\n",
        "print(NEWMODELNAME)\n",
        "# create a TensorBoard callback to visualize training metrics\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# # Create the TrialCheckpoint callback\n",
        "# class MyModelCheckpoint (ModelCheckpoint):\n",
        "#     def __init__(self, *args, **kwargs):\n",
        "#         self.now = 0\n",
        "#         super(MyModelCheckpoint, self).__init__(\n",
        "#             filepath = self.get_chpt_dir(),\n",
        "#             save_weights_only=False,\n",
        "#             save_best_only=True,\n",
        "#             save_freq='epoch',\n",
        "#             verbose=1\n",
        "#         )\n",
        "        \n",
        "    \n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "#         super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)\n",
        "#         self.now = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        " \n",
        "    \n",
        "#     def get_chpt_dir(self):\n",
        "#         return f\"Checkpoint/{NEWMODELNAME}/{self.now}_\"+\"{epoch:02d}.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "tuner.search(train_ds, epochs=20, validation_data=test_ds,callbacks=[tensorboard_callback]) #MyModelCheckpoint(), "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Results (Tuner)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 30 best trials\n",
            "Objective(name=\"val_recall\", direction=\"max\")\n",
            "\n",
            "Trial 17 summary\n",
            "Hyperparameters:\n",
            "conv1: 1\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 0\n",
            "conv3_block3: 1\n",
            "conv3_block4: 1\n",
            "Score: 0.772455096244812\n",
            "\n",
            "Trial 38 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.772455096244812\n",
            "\n",
            "Trial 32 summary\n",
            "Hyperparameters:\n",
            "conv1: 1\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 0\n",
            "Score: 0.772455096244812\n",
            "\n",
            "Trial 31 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 0\n",
            "conv3_block3: 1\n",
            "conv3_block4: 0\n",
            "Score: 0.772455096244812\n",
            "\n",
            "Trial 30 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.772455096244812\n",
            "\n",
            "Trial 36 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.772455096244812\n",
            "\n",
            "Trial 35 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.772455096244812\n",
            "\n",
            "Trial 37 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.772455096244812\n",
            "\n",
            "Trial 44 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 0\n",
            "conv3_block3: 1\n",
            "conv3_block4: 0\n",
            "Score: 0.772455096244812\n",
            "\n",
            "Trial 27 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 0\n",
            "conv2_block3: 0\n",
            "conv3_block1: 0\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7664670944213867\n",
            "\n",
            "Trial 46 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7664670944213867\n",
            "\n",
            "Trial 12 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7664670944213867\n",
            "\n",
            "Trial 41 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 0\n",
            "conv3_block3: 1\n",
            "conv3_block4: 0\n",
            "Score: 0.7664670944213867\n",
            "\n",
            "Trial 26 summary\n",
            "Hyperparameters:\n",
            "conv1: 1\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 0\n",
            "conv3_block2: 0\n",
            "conv3_block3: 1\n",
            "conv3_block4: 0\n",
            "Score: 0.7664670944213867\n",
            "\n",
            "Trial 19 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 1\n",
            "conv2_block2: 0\n",
            "conv2_block3: 1\n",
            "conv3_block1: 0\n",
            "conv3_block2: 0\n",
            "conv3_block3: 0\n",
            "conv3_block4: 0\n",
            "Score: 0.7664670944213867\n",
            "\n",
            "Trial 18 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 1\n",
            "conv2_block2: 0\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 1\n",
            "conv3_block4: 0\n",
            "Score: 0.7664670944213867\n",
            "\n",
            "Trial 39 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7664670944213867\n",
            "\n",
            "Trial 29 summary\n",
            "Hyperparameters:\n",
            "conv1: 1\n",
            "conv2_block1: 1\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 0\n",
            "conv3_block2: 0\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7664670944213867\n",
            "\n",
            "Trial 48 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 0\n",
            "conv3_block3: 1\n",
            "conv3_block4: 0\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 13 summary\n",
            "Hyperparameters:\n",
            "conv1: 1\n",
            "conv2_block1: 0\n",
            "conv2_block2: 0\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 0\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 47 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 49 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 0\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 45 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 0\n",
            "conv3_block3: 1\n",
            "conv3_block4: 0\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 1\n",
            "conv2_block2: 0\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 10 summary\n",
            "Hyperparameters:\n",
            "conv1: 1\n",
            "conv2_block1: 1\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 0\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 24 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 1\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 0\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 0\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 20 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 1\n",
            "conv3_block1: 0\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 14 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 1\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 0\n",
            "conv3_block3: 1\n",
            "conv3_block4: 1\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 0\n",
            "conv2_block2: 0\n",
            "conv2_block3: 1\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 1\n",
            "conv3_block4: 0\n",
            "Score: 0.7604790329933167\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "conv1: 0\n",
            "conv2_block1: 1\n",
            "conv2_block2: 0\n",
            "conv2_block3: 0\n",
            "conv3_block1: 1\n",
            "conv3_block2: 1\n",
            "conv3_block3: 0\n",
            "conv3_block4: 1\n",
            "Score: 0.7604790329933167\n"
          ]
        }
      ],
      "source": [
        "tuner.results_summary(num_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_hps = tuner.get_best_hyperparameters(num_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = ds_generator(\"dcrpi-167\", 16 , True,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i,hps in enumerate(all_hps):\n",
        "    print(f\"best trial - {i}\")\n",
        "    tuned_model = build_model(hps)\n",
        "    tuned_model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=build_model(all_hps[0]).save(f\"Models/{NEWMODELNAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(f\"Models/{NEWMODELNAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = ds_generator(path=\"dcrpi-167\",batch_size=1,to_1_hot= False,shuffle=False)\n",
        "preds = model.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_preds = np.argmax(preds, axis=1)\n",
        "\n",
        "Y = []\n",
        "for images, labels in test_ds:\n",
        "    for label in labels:\n",
        "        Y.append(label)\n",
        "\n",
        "y_test = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.floor(4.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_images(i_s,images):\n",
        "    mid = (len(images))**0.5\n",
        "\n",
        "    nrows = int(np.ceil(mid))\n",
        "    ncols = int(np.floor(mid))\n",
        "    class_names = ['can','paper','plastic']\n",
        "    plt.figure(figsize=(14, 14))\n",
        "    # for images, labels in train_ds.take(1):\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(nrows, ncols, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(f\"P-{class_names[y_preds[i_s[i]]]} A-{class_names[y_test[i_s[i]]]}\")\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = ['can','paper','plastic']\n",
        "images = []\n",
        "i_s = []\n",
        "for i, (image, label) in enumerate(test_ds):\n",
        "    if y_test[i] != y_preds[i]:\n",
        "        im = tf.squeeze(image)\n",
        "        if i==0: \n",
        "            print(im.shape)\n",
        "        images.append(im)\n",
        "        i_s.append(i)\n",
        "show_images(i_s,images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(y_test,y_preds)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = ds_generator(\"dataset\", 16, True)\n",
        "test_ds = ds_generator(\"dcrpi-167\", 16, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[tf.metrics.Recall() ])\n",
        "\n",
        "log_dir = f\"logs/{NEWMODELNAME}_p\"\n",
        "tf.keras.losses.mean_absolute_error\n",
        "# create a TensorBoard callback to visualize training metricsf\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath = f'Tuner/{NEWMODELNAME}_p/'+'{epoch:02d}.h5',\n",
        "    save_weights_only=False,\n",
        "    save_best_only=True,\n",
        "    save_freq='epoch',\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(  train_ds, \n",
        "validation_data=test_ds,\n",
        "callbacks=[checkpoint_callback,tensorboard_callback],\n",
        "epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.layers[-1].get_config()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
