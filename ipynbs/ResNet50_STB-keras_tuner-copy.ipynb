{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCHzhg9NzOtF"
      },
      "source": [
        "# **Importing Important Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "class ZerosFirstEpochOnesAfter(tf.keras.utils.Sequence):\n",
        "    def __init__(self):\n",
        "        self.is_epoch_0 = True\n",
        "\n",
        "    def __len__(self):\n",
        "        return 2\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "      print('\\non_epoch_end')\n",
        "      self.is_epoch_0 = False\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if self.is_epoch_0:\n",
        "            print(\"\\nFirst epoch\")\n",
        "            return np.zeros((160, 1)), np.zeros((160,))\n",
        "        else:\n",
        "            return np.ones((160, 1)), np.full((160,), 99)\n",
        "\n",
        "\n",
        "class OnEpochEnd(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, callbacks):\n",
        "    self.callbacks = callbacks\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    for callback in self.callbacks:\n",
        "      callback()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(1, input_dim=1, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='Adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    seq = ZerosFirstEpochOnesAfter()\n",
        "    \n",
        "    model.fit(seq, epochs=3,callbacks=[OnEpochEnd([seq.on_epoch_end])]) #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.experimental.list_physical_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(gpus)\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "       tf.config.experimental.set_memory_growth(gpu,True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(gpus)\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_virtual_device_configuration(gpu,[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12288)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pathlib \n",
        "import os \n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV2ti6FlyNgo"
      },
      "source": [
        "# **Loading and Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RJHKx5Q31ubO"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path(\"dataset\")\n",
        "# print(len(list(data_dir.glob(\"*/*\"))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "OZAKa51slzkX",
        "outputId": "b589f0e5-566f-4031-a116-cdd6450d1cd7"
      },
      "outputs": [],
      "source": [
        "trash = list(data_dir.glob('Can/1/*'))\n",
        "PIL.Image.open(str(trash[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NX_bMiF56hOK"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "image_height = 224\n",
        "image_width = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names=['Can','Paper','Plastic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnlvnNd9yblJ",
        "outputId": "1bec4d8e-eb9e-4c99-f8f1-435d18c3e7cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 62651 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# with tf.device(\"CPU\"):\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  # validation_split=0.1,\n",
        "  # subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size,\n",
        "  # class_names=class_names\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 167 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "test_dir = pathlib.Path(\"dcrpi-167\")\n",
        "\n",
        "# with tf.device(\"CPU\"):\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  # class_names = class_names,\n",
        "  batch_size=batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a function to convert labels to one-hot encoding\n",
        "num_classes = 3\n",
        "def to_one_hot(x, y):\n",
        "    num_classes = 3\n",
        "    y_one_hot = tf.one_hot(y, num_classes)\n",
        "    return x, y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# val_ds = val_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = test_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQRrm5zo0F4x"
      },
      "source": [
        "# **Configure Dataset Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI4zGCvrzw9t"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "# val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds= test_ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = tf.keras.models.load_model(\"Models/ResNet50-STBv1.0_16\")\n",
        "    \n",
        "    # Setting Resnet50 to be false\n",
        "    for layer in model.layers[2].layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    if hp.Choice(\"conv1\",[True,False]):\n",
        "        for layer in model.layers[2].layers[1:7]:\n",
        "            layer.trainable = True\n",
        "        \n",
        "    if hp.Choice(\"conv2_block1\",[True,False]):\n",
        "        for layer in model.layers[2].layers[7:19]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv2_block2\",[True,False]):\n",
        "        for layer in model.layers[2].layers[19:29]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    if hp.Choice(\"conv2_block3\",[True,False]):\n",
        "        for layer in model.layers[2].layers[29:39]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv3_block1\",[True,False]):\n",
        "        for layer in model.layers[2].layers[39:51]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    if hp.Choice(\"conv3_block2\",[True,False]):\n",
        "        for layer in model.layers[2].layers[51:61]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv3_block3\",[True,False]):\n",
        "        for layer in model.layers[2].layers[61:71]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    if hp.Choice(\"conv3_block4\",[True,False]):\n",
        "        for layer in model.layers[2].layers[71:81]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    # if hp.Choice(\"conv4_block1\",[True,False]):\n",
        "    #     for layer in model.layers[2].layers[81:93]:\n",
        "    #         layer.trainable = True\n",
        "    \n",
        "    # if hp.Choice(\"conv4_block2\",[True,False]):\n",
        "    #     for layer in model.layers[2].layers[93:103]:\n",
        "    #         layer.trainable = True\n",
        "    \n",
        "    # if hp.Choice(\"conv4_block3\",[True,False]):\n",
        "    #     for layer in model.layers[2].layers[103:113]:\n",
        "    #         layer.trainable = True\n",
        "    \n",
        "    # if hp.Choice(\"conv4_block4\",[True,False]):\n",
        "    #     for layer in model.layers[2].layers[113:123]:\n",
        "    #         layer.trainable = True\n",
        "    \n",
        "    # if hp.Choice(\"conv4_block5\",[True,False]):\n",
        "    #     for layer in model.layers[2].layers[123:133]:\n",
        "    #         layer.trainable = True\n",
        "    \n",
        "    # if hp.Choice(\"conv4_block6\",[True,False]):\n",
        "    #     for layer in model.layers[2].layers[133:143]:\n",
        "    #         layer.trainable = True\n",
        "    \n",
        "    # if hp.Choice(\"conv5_block1\",[True,False]):\n",
        "    #     for layer in model.layers[2].layers[143:155]:\n",
        "    #         layer.trainable = True\n",
        "\n",
        "    # if hp.Choice(\"conv5_block2\",[True,False]):\n",
        "    #     for layer in model.layers[2].layers[155:165]:\n",
        "    #         layer.trainable = True\n",
        "    \n",
        "    # if hp.Choice(\"conv5_block3\",[True,False]):\n",
        "    #     for layer in model.layers[2].layers[165:]:\n",
        "    #         layer.trainable = True\n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "# Define the hyperparameters\n",
        "hp = HyperParameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install keras-tuner --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras_tuner import Hyperband, Objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ],
      "source": [
        "tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective=Objective('val_accuracy', direction='max'),\n",
        "    max_epochs=25,\n",
        "    factor=3,\n",
        "    overwrite=True,\n",
        "    directory='Tuner/ResNet50-STBv1.0_17',\n",
        "    project_name='HB_tuner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 8\n",
            "conv1 (Choice)\n",
            "{'default': 1, 'conditions': [], 'values': [1, 0], 'ordered': True}\n",
            "conv2_block1 (Choice)\n",
            "{'default': 1, 'conditions': [], 'values': [1, 0], 'ordered': True}\n",
            "conv2_block2 (Choice)\n",
            "{'default': 1, 'conditions': [], 'values': [1, 0], 'ordered': True}\n",
            "conv2_block3 (Choice)\n",
            "{'default': 1, 'conditions': [], 'values': [1, 0], 'ordered': True}\n",
            "conv3_block1 (Choice)\n",
            "{'default': 1, 'conditions': [], 'values': [1, 0], 'ordered': True}\n",
            "conv3_block2 (Choice)\n",
            "{'default': 1, 'conditions': [], 'values': [1, 0], 'ordered': True}\n",
            "conv3_block3 (Choice)\n",
            "{'default': 1, 'conditions': [], 'values': [1, 0], 'ordered': True}\n",
            "conv3_block4 (Choice)\n",
            "{'default': 1, 'conditions': [], 'values': [1, 0], 'ordered': True}\n"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary(extended=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a log directory for TensorBoard\n",
        "log_dir = \"logs/ResNet50-STBv1.0_17\"\n",
        "\n",
        "# create a TensorBoard callback to visualize training metrics\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the TrialCheckpoint callback\n",
        "class MyModelCheckpoint (ModelCheckpoint):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MyModelCheckpoint, self).__init__(\n",
        "            filepath = self.get_chpt_dir(),\n",
        "            save_weights_only=False,\n",
        "            save_best_only=True,\n",
        "            save_freq='epoch',\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "    def get_now(self):\n",
        "        now = datetime.now()\n",
        "        now = now.strftime(\"%Y%m%d%H%M%S\")\n",
        "        return now\n",
        "\n",
        "    \n",
        "    def get_chpt_dir(self):\n",
        "        return f\"Checkpoint/ResNet50-STBv1.0_17/{trial.trial_id}{self.get_now().}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = tf.keras.models.load_model(\"Tuner/ResNet50-STBv1.0_7/resnet50_stb_v1_0_7.02.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 1s 29ms/step - loss: 2.2109 - accuracy: 0.4491\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.210906744003296, 0.4491018056869507]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_models = tuner.get_best_models(num_models=28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3916/3916 [==============================] - ETA: 0s - loss: 1.6222e-04 - accuracy: 0.9999\n",
            "Epoch 16: val_loss did not improve from 1.69591\n",
            "3916/3916 [==============================] - 351s 90ms/step - loss: 1.6222e-04 - accuracy: 0.9999 - val_loss: 2.3715 - val_accuracy: 0.7006\n",
            "Epoch 17/25\n",
            "3916/3916 [==============================] - ETA: 0s - loss: 2.8864e-05 - accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 1.69591\n",
            "3916/3916 [==============================] - 350s 89ms/step - loss: 2.8864e-05 - accuracy: 1.0000 - val_loss: 2.5266 - val_accuracy: 0.6886\n",
            "Epoch 18/25\n",
            "2881/3916 [=====================>........] - ETA: 1:32 - loss: 1.8896e-04 - accuracy: 1.0000"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(train_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mtest_ds,callbacks\u001b[39m=\u001b[39;49m[MyModelCheckpoint(), tensorboard_callback])\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras_tuner/tuners/hyperband.py:425\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/epochs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    424\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/initial_epoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 425\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras/engine/training.py:1691\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1690\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1691\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1692\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1693\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras/callbacks.py:390\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    388\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 390\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_logs(logs, is_batch_hook\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._process_logs\u001b[0;34m(self, logs, is_batch_hook)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m is_batch_hook \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_hooks_support_tf_logs:\n\u001b[1;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m logs\n\u001b[0;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras/utils/tf_utils.py:680\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    678\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/keras/utils/tf_utils.py:673\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    671\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 673\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    674\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1160\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
            "File \u001b[0;32m~/Desktop/sdp/test_1/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1126\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1125\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1127\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tuner.search(train_ds, epochs=25, validation_data=test_ds,callbacks=[MyModelCheckpoint(), tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feqwWGoSmvbD"
      },
      "source": [
        "## Evaluation and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"Models/ResNet50-STBv1.0_6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 167 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "test_dir = pathlib.Path(\"dcrpi-167\")\n",
        "image_height, image_width = 224, 224\n",
        "# with tf.device(\"CPU\"):\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=1\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = test_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFUefrUhm7qd",
        "outputId": "07b66ae6-a5e6-4e95-f065-c84415e3912e"
      },
      "outputs": [],
      "source": [
        "loss, precision = model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ],
      "source": [
        "num_models = 28\n",
        "all_models = tuner.get_best_models(num_models=num_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0-best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-10 01:40:56.818629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [167]\n",
            "\t [[{{node Placeholder/_4}}]]\n",
            "2023-04-10 01:40:56.818868: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [167]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "167/167 [==============================] - 2s 7ms/step - loss: 1.9320 - accuracy: 0.3832\n",
            "1-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.6627 - accuracy: 0.7545\n",
            "2-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.9213 - accuracy: 0.7545\n",
            "3-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.3871 - accuracy: 0.7425\n",
            "4-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.9280 - accuracy: 0.7485\n",
            "5-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.8094 - accuracy: 0.7425\n",
            "6-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.9033 - accuracy: 0.7365\n",
            "7-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.9026 - accuracy: 0.7365\n",
            "8-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.6752 - accuracy: 0.7365\n",
            "9-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.7715 - accuracy: 0.7305\n",
            "10-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.9779 - accuracy: 0.7246\n",
            "11-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.7663 - accuracy: 0.7246\n",
            "12-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.8965 - accuracy: 0.7126\n",
            "13-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 2.1526 - accuracy: 0.7126\n",
            "14-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 2.0547 - accuracy: 0.7066\n",
            "15-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.9202 - accuracy: 0.7006\n",
            "16-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 2.2514 - accuracy: 0.7006\n",
            "17-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 2.0178 - accuracy: 0.7006\n",
            "18-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 2.1140 - accuracy: 0.6826\n",
            "19-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.8759 - accuracy: 0.6766\n",
            "20-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.7652 - accuracy: 0.6766\n",
            "21-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.6208 - accuracy: 0.6587\n",
            "22-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 2.2124 - accuracy: 0.6527\n",
            "23-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 2.1022 - accuracy: 0.6467\n",
            "24-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.8953 - accuracy: 0.6347\n",
            "25-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 2.0354 - accuracy: 0.6228\n",
            "26-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 2.6004 - accuracy: 0.6168\n",
            "27-best model\n",
            "167/167 [==============================] - 2s 6ms/step - loss: 1.9406 - accuracy: 0.7425\n"
          ]
        }
      ],
      "source": [
        "tuner_results = {}\n",
        "for i,model in enumerate(all_models):\n",
        "    print(f\"{i}-best model\")\n",
        "    l,p = model.evaluate(test_ds)\n",
        "    tuner_results[i] = [l,p]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-10 01:43:38.698990: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'random_flip_input' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node random_flip_input}}]]\n",
            "2023-04-10 01:43:38.747680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:38.755194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'random_flip_input' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node random_flip_input}}]]\n",
            "2023-04-10 01:43:38.766208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:38.772646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:38.780653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:41.930000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_2' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node input_2}}]]\n",
            "2023-04-10 01:43:42.133686: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:42.287669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_2' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node input_2}}]]\n",
            "2023-04-10 01:43:42.660891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:42.737673: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:43.263535: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:43.965178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:44.922828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:44.948870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "2023-04-10 01:43:44.975903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,224,224,3]\n",
            "\t [[{{node inputs}}]]\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ResNet50-STBv1.0_17/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Models/ResNet50-STBv1.0_17/assets\n"
          ]
        }
      ],
      "source": [
        "best_model_1 = all_models[1]\n",
        "best_model_1.save(\"Models/ResNet50-STBv1.0_17\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "with open('tuner_result.json', 'w') as fp:\n",
        "    json.dump(tuner_results, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUajWQvrsE5f"
      },
      "outputs": [],
      "source": [
        "num_trials = 15\n",
        "from kerastuner import HyperParameters\n",
        "tuner_hps_summary = tuner.get_best_hyperparameters(num_trials=num_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN8BYWee5vhr",
        "outputId": "57df625c-ae8a-4b14-a62e-94f32b89b151"
      },
      "outputs": [],
      "source": [
        "summary_dict = {}\n",
        "for i,a in enumerate(tuner_hps_summary):\n",
        "  print(f\"Best trial {i}:\")\n",
        "\n",
        "  trial_dict = {}\n",
        "  for hp_name, hp_value in a.values.items():\n",
        "      # print(f\"{hp_value}\")\n",
        "      trial_dict[hp_name] = hp_value\n",
        "  summary_dict[i] = trial_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOBMQpwy5DMP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a pandas DataFrame from the dictionary\n",
        "df = pd.DataFrame.from_dict(summary_dict, orient='index')\n",
        "\n",
        "# Write the DataFrame to an excel file\n",
        "df.to_excel('/content/drive/My Drive/Models/output-3_1.xlsx', na_rep='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQM_57QYsx0e"
      },
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters:\")\n",
        "\n",
        "for i,trial in enumerate(tuner_hps_summary):\n",
        "  print(f\"Trial {i}\")\n",
        "  for hp_name, hp_value in trial.values.items():\n",
        "      print(f\"- {hp_name}: {hp_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIv36xGLUZOK"
      },
      "source": [
        "## Convert to TfLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"Models/ResNet50-STBv1.0_13\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdZquiRGUgVB",
        "outputId": "e44056c1-7f17-49ea-c11c-cd177f2dc51b"
      },
      "outputs": [],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('Models/ResNet50-STBv1.0_13.Lite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaTZcGrqbssG",
        "outputId": "263f3a68-f71e-41e5-a098-f6ba3279d731"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
