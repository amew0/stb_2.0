{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SCHzhg9NzOtF"
      },
      "source": [
        "# **Importing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ai-05/Desktop/sdp\n"
          ]
        }
      ],
      "source": [
        "%cd /home/ai-05/Desktop/sdp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-14 20:36:04.556406: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-04-14 20:36:04.575989: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-04-14 20:36:04.705922: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-04-14 20:36:04.707115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-14 20:36:05.626423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPUs: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-14 20:36:08.851078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-14 20:36:08.932747: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "utils.set_gpu_memo_limit(5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NEWMODELNAME = \"ResNet50-STBv1.0_19\"\n",
        "BASEMODELNAME = \"ResNet50-STBv1.0_18\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = ds_generator(\"dataset\", 16, True)\n",
        "test_ds = ds_generator(\"dcrpi-167\", 16,True, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Prep**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_layer_index = {\n",
        "    0: [1,7,'conv1'],\n",
        "    1: [7,19,'conv2_block1'],\n",
        "    2: [19,29,'conv2_block2'],\n",
        "    3: [29,39,'conv2_block3'],\n",
        "    4: [39,51,'conv3_block1'],\n",
        "    5: [51,61,'conv3_block2'],\n",
        "    6: [61,71,'conv3_block3'],\n",
        "    7: [71,81,'conv3_block4'],\n",
        "    8: [81,93,'conv4_block1'],\n",
        "    9: [93,103,'conv4_block2'],\n",
        "    10: [103,113,'conv4_block3'],\n",
        "    11: [113,123,'conv4_block4'],\n",
        "    12: [123, 133,'conv4_block5'],\n",
        "    13: [133,143,'conv4_block6'],\n",
        "    14: [143,155,'conv5_block1'],\n",
        "    15: [155,165,'conv5_block2'],\n",
        "    16: [165, -1,'conv5_block3']\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(f\"Models/{BASEMODELNAME}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Tuner**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner_path = f'Tuner/{BASEMODELNAME}'\n",
        "num_trials = 30\n",
        "tunable_indices = [8,9,10,11,12,13,14,15,16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comp(hps, d_i):\n",
        "    # compares two dicts if they are equal \n",
        "    for k in hps:\n",
        "        if k not in d_i.index or  hps[k] != d_i[k]: return False\n",
        "        else: continue\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    \n",
        "    resnet_base = model.layers[2]\n",
        "    resnet_base.trainable = False\n",
        "\n",
        "    name = lambda i: block_layer_index[i][2]\n",
        "    names = list(map(name, tunable_indices))\n",
        "\n",
        "    hps = {}\n",
        "    for i,name_ in enumerate(names):\n",
        "        hps[name_] = hp.Choice(name_, [True,False]) == True\n",
        "    \n",
        "    d = retrieve_trials( tuner_path, num_trials, tunable_indices)\n",
        "    exists = True\n",
        "    while exists:\n",
        "        checks = []\n",
        "        for i in range(len(d.columns)):\n",
        "            equal = comp(hps,d[i])\n",
        "            checks.append(equal)\n",
        "            if equal: break\n",
        "        checks = np.array(checks)\n",
        "        exists = np.any(checks) # If there is any True value returns True\n",
        "        \n",
        "        if exists:\n",
        "            print(f\"HP combination already exists with the following values:{hps}\")\n",
        "        else:print(f\"HP combination is new.\\n{hps}\")\n",
        "             \n",
        "        # Flip the value of the boolean at the chosen key\n",
        "        flip_key = random.choice(tunable_indices)\n",
        "        flip_key = name(flip_key)\n",
        "        hps[flip_key] = not hps[flip_key]\n",
        "\n",
        "    for bli_k, bli_v in block_layer_index.items():\n",
        "        if bli_k in tunable_indices:\n",
        "            for layer in resnet_base.layers[bli_v[0]:bli_v[1]]:\n",
        "                layer.trainable = hps[name(bli_k)]\n",
        "        \n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[tf.metrics.Recall()])\n",
        "    return model\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "# Define the hyperparameters\n",
        "hp = HyperParameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective=Objective('val_recall', direction='max'),\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    overwrite=True,\n",
        "    directory=f'Tuner/{NEWMODELNAME}',\n",
        "    project_name='HB_tuner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner.search_space_summary(extended=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_dir = f\"logs/{NEWMODELNAME}\"\n",
        "\n",
        "# create a TensorBoard callback to visualize training metrics\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Create the TrialCheckpoint callback\n",
        "class MyModelCheckpoint (ModelCheckpoint):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.now = 0\n",
        "        super(MyModelCheckpoint, self).__init__(\n",
        "            filepath = self.get_chpt_dir(),\n",
        "            save_weights_only=False,\n",
        "            save_best_only=True,\n",
        "            save_freq='epoch',\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)\n",
        "        self.now = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        " \n",
        "    \n",
        "    def get_chpt_dir(self):\n",
        "        return f\"Checkpoint/{NEWMODELNAME}/{self.now}_\"+\"{epoch:02d}.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner.search(train_ds, epochs=20, validation_data=test_ds,callbacks=[MyModelCheckpoint(), tensorboard_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Results (Tuner)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner.results_summary(num_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_hps = tuner.get_best_hyperparameters(num_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = ds_generator(\"dcrpi-167\", 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i,hps in enumerate(all_hps):\n",
        "    print(f\"best trial - {i}\")\n",
        "    tuned_model = build_model(hps)\n",
        "    tuned_model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "build_model(all_hps[0]).save(f\"Models/{NEWMODELNAME}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(f\"Models/{NEWMODELNAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = ds_generator(path=\"dcrpi-167\",batch_size=1,to_1_hot= False,shuffle=False)\n",
        "preds = model.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_preds = np.argmax(preds, axis=1)\n",
        "\n",
        "Y = []\n",
        "for images, labels in test_ds:\n",
        "    for label in labels:\n",
        "        Y.append(label)\n",
        "\n",
        "y_test = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_images(i_s,images):\n",
        "    nrows = 7\n",
        "    ncols = 6\n",
        "    class_names = ['can','paper','plastic']\n",
        "    plt.figure(figsize=(14, 14))\n",
        "    # for images, labels in train_ds.take(1):\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(nrows, ncols, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(f\"P-{class_names[y_preds[i_s[i]]]} A-{class_names[y_test[i_s[i]]]}\")\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = ['can','paper','plastic']\n",
        "images = []\n",
        "i_s = []\n",
        "for i, (image, label) in enumerate(test_ds):\n",
        "    if y_test[i] != y_preds[i]:\n",
        "        im = tf.squeeze(image)\n",
        "        if i==0: \n",
        "            print(im.shape)\n",
        "        images.append(im)\n",
        "        i_s.append(i)\n",
        "show_images(i_s,images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(y_test,y_preds)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = ds_generator(\"dataset\", 16, True)\n",
        "test_ds = ds_generator(\"dcrpi-167\", 16, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[tf.metrics.Recall() ])\n",
        "\n",
        "log_dir = f\"logs/{NEWMODELNAME}_p\"\n",
        "tf.keras.losses.mean_absolute_error\n",
        "# create a TensorBoard callback to visualize training metricsf\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath = f'Tuner/{NEWMODELNAME}_p/'+'{epoch:02d}.h5',\n",
        "    save_weights_only=False,\n",
        "    save_best_only=True,\n",
        "    save_freq='epoch',\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(  train_ds, \n",
        "validation_data=test_ds,\n",
        "callbacks=[checkpoint_callback,tensorboard_callback],\n",
        "epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.layers[-1].get_config()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
