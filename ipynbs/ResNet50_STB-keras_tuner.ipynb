{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCHzhg9NzOtF"
      },
      "source": [
        "# **Importing Important Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QGA54rw6ZGJL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pathlib \n",
        "import os \n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV2ti6FlyNgo"
      },
      "source": [
        "# **Loading and Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RJHKx5Q31ubO"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path(\"Custom-Dataset\")\n",
        "# print(len(list(data_dir.glob(\"*/*\"))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "OZAKa51slzkX",
        "outputId": "b589f0e5-566f-4031-a116-cdd6450d1cd7"
      },
      "outputs": [],
      "source": [
        "trash = list(data_dir.glob('Can/*'))\n",
        "PIL.Image.open(str(trash[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NX_bMiF56hOK"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "image_height = 224\n",
        "image_width = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnlvnNd9yblJ",
        "outputId": "1bec4d8e-eb9e-4c99-f8f1-435d18c3e7cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 23343 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  # validation_split=0.1,\n",
        "  # subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Vp2LKLy8LH",
        "outputId": "d17d47ba-995d-49fe-95c7-b64c929731f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21000 files belonging to 3 classes.\n",
            "Using 2100 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.1,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQRrm5zo0F4x"
      },
      "source": [
        "# **Configure Dataset Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vI4zGCvrzw9t"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "# val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds= test_ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oW56T4OhIa3S"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyg3nqILNFe3",
        "outputId": "ff2357d6-f22c-473c-ff7a-33d17c735af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(\"Models/ResNet50-STBv1.0_13\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(\"Models/ResNet50-STBv1.0_13\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,178,819\n",
            "Trainable params: 18,842,499\n",
            "Non-trainable params: 5,336,320\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = tf.keras.models.load_model(\"Models/ResNet50-STBv1.0_13\")\n",
        "    \n",
        "    # Setting Resnet50 to be false\n",
        "    for layer in model.layers[2].layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    if hp.Choice(\"conv1\",[True,False]):\n",
        "        for layer in model.layers[2].layers[1:7]:\n",
        "            layer.trainable = True\n",
        "        \n",
        "    if hp.Choice(\"conv2_block1\",[True,False]):\n",
        "        for layer in model.layers[2].layers[7:19]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv2_block2\",[True,False]):\n",
        "        for layer in model.layers[2].layers[19:29]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    if hp.Choice(\"conv2_block3\",[True,False]):\n",
        "        for layer in model.layers[2].layers[29:39]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv3_block1\",[True,False]):\n",
        "        for layer in model.layers[2].layers[39:51]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    if hp.Choice(\"conv3_block2\",[True,False]):\n",
        "        for layer in model.layers[2].layers[51:61]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv3_block3\",[True,False]):\n",
        "        for layer in model.layers[2].layers[61:71]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    if hp.Choice(\"conv3_block4\",[True,False]):\n",
        "        for layer in model.layers[2].layers[71:81]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    if hp.Choice(\"conv4_block1\",[True,False]):\n",
        "        for layer in model.layers[2].layers[81:93]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv4_block2\",[True,False]):\n",
        "        for layer in model.layers[2].layers[93:103]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv4_block3\",[True,False]):\n",
        "        for layer in model.layers[2].layers[103:113]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv4_block4\",[True,False]):\n",
        "        for layer in model.layers[2].layers[113:123]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv4_block5\",[True,False]):\n",
        "        for layer in model.layers[2].layers[123:133]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv4_block6\",[True,False]):\n",
        "        for layer in model.layers[2].layers[133:143]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv5_block1\",[True,False]):\n",
        "        for layer in model.layers[2].layers[143:155]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    if hp.Choice(\"conv5_block2\",[True,False]):\n",
        "        for layer in model.layers[2].layers[155:165]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    if hp.Choice(\"conv5_block3\",[True,False]):\n",
        "        for layer in model.layers[2].layers[165:]:\n",
        "            layer.trainable = True\n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-d3216093274a>:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.engine.hyperparameters import HyperParameters\n"
          ]
        }
      ],
      "source": [
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "# Define the hyperparameters\n",
        "hp = HyperParameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install keras-tuner --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kerastuner import Hyperband"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras_tuner import Objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ],
      "source": [
        "tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective=Objective('val_accuracy', direction='max'),\n",
        "    max_epochs=25,\n",
        "    factor=3,\n",
        "    overwrite=False,\n",
        "    directory='Tuner/ResNet50-STBv1.0_15',\n",
        "    project_name='HB_tuner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 25 Complete [15h 00m 24s]\n",
            "val_accuracy: 0.625\n",
            "\n",
            "Best val_accuracy So Far: 0.6458333134651184\n",
            "Total elapsed time: 4d 04h 12m 07s\n",
            "\n",
            "Search: Running Trial #26\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "1                 |1                 |conv1\n",
            "0                 |0                 |conv2_block1\n",
            "0                 |0                 |conv2_block2\n",
            "1                 |1                 |conv2_block3\n",
            "1                 |1                 |conv3_block1\n",
            "1                 |1                 |conv3_block2\n",
            "1                 |1                 |conv3_block3\n",
            "1                 |1                 |conv3_block4\n",
            "1                 |0                 |conv4_block1\n",
            "1                 |0                 |conv4_block2\n",
            "0                 |1                 |conv4_block3\n",
            "0                 |0                 |conv4_block4\n",
            "0                 |1                 |conv4_block5\n",
            "0                 |0                 |conv4_block6\n",
            "1                 |0                 |conv5_block1\n",
            "1                 |1                 |conv5_block2\n",
            "0                 |0                 |conv5_block3\n",
            "25                |9                 |tuner/epochs\n",
            "9                 |0                 |tuner/initial_epoch\n",
            "1                 |1                 |tuner/bracket\n",
            "1                 |0                 |tuner/round\n",
            "0018              |None              |tuner/trial_id\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/25\n",
            "730/730 [==============================] - 3481s 5s/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 2.5864 - val_accuracy: 0.6146\n",
            "Epoch 11/25\n",
            "730/730 [==============================] - 3487s 5s/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 3.4475 - val_accuracy: 0.5208\n",
            "Epoch 12/25\n",
            "404/730 [===============>..............] - ETA: 25:59 - loss: 0.0169 - accuracy: 0.9954"
          ]
        }
      ],
      "source": [
        "tuner.search(train_ds, epochs=25, validation_data=test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a function to convert labels to one-hot encoding\n",
        "num_classes = 3\n",
        "def to_one_hot(x, y):\n",
        "    num_classes = 3\n",
        "    y_one_hot = tf.one_hot(y, num_classes)\n",
        "    return x, y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_ds = val_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = test_ds.map(to_one_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feqwWGoSmvbD"
      },
      "source": [
        "## Evaluation and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsI3TeIrm3YM",
        "outputId": "812555b5-49ca-421c-adfe-38ddb5673d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 96 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Evaluating on a new dataset from the internet\n",
        "# paper and plastic from  https://www.kaggle.com/datasets/arthurcen/waste-images-from-sushi-restaurant\n",
        "# can from https://universe.roboflow.com/dataset-t7hz7/cans-fdboa/dataset/1\n",
        "# test_dir = pathlib.Path(\"Dataset-testing (from internet)\")\n",
        "# test_dir = pathlib.Path(\"WasteImagesDataset\")\n",
        "test_dir = pathlib.Path(\"data-camera-rpi\")\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "image_height = 224\n",
        "image_width = 224\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  seed=123,\n",
        "  image_size=(image_height, image_width),\n",
        "  batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFUefrUhm7qd",
        "outputId": "07b66ae6-a5e6-4e95-f065-c84415e3912e"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print('Test accuracy :', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_models = 30\n",
        "all_models = tuner.get_best_models(num_models=num_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner_results = {}\n",
        "for i,model in enumerate(all_models):\n",
        "    print(f\"{i}-best model\")\n",
        "    l,p = model.evaluate(test_ds)\n",
        "    tuner_results[i] = [l,p]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model_1 = all_models[14]\n",
        "best_model_1.save(\"Models/ResNet50-STBv1.0_12\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "with open('tuner_result.json', 'w') as fp:\n",
        "    json.dump(tuner_results, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUajWQvrsE5f"
      },
      "outputs": [],
      "source": [
        "num_trials = 15\n",
        "from kerastuner import HyperParameters\n",
        "tuner_hps_summary = tuner.get_best_hyperparameters(num_trials=num_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN8BYWee5vhr",
        "outputId": "57df625c-ae8a-4b14-a62e-94f32b89b151"
      },
      "outputs": [],
      "source": [
        "summary_dict = {}\n",
        "for i,a in enumerate(tuner_hps_summary):\n",
        "  print(f\"Best trial {i}:\")\n",
        "\n",
        "  trial_dict = {}\n",
        "  for hp_name, hp_value in a.values.items():\n",
        "      # print(f\"{hp_value}\")\n",
        "      trial_dict[hp_name] = hp_value\n",
        "  summary_dict[i] = trial_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOBMQpwy5DMP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a pandas DataFrame from the dictionary\n",
        "df = pd.DataFrame.from_dict(summary_dict, orient='index')\n",
        "\n",
        "# Write the DataFrame to an excel file\n",
        "df.to_excel('/content/drive/My Drive/Models/output-3_1.xlsx', na_rep='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQM_57QYsx0e"
      },
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters:\")\n",
        "\n",
        "for i,trial in enumerate(tuner_hps_summary):\n",
        "  print(f\"Trial {i}\")\n",
        "  for hp_name, hp_value in trial.values.items():\n",
        "      print(f\"- {hp_name}: {hp_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIv36xGLUZOK"
      },
      "source": [
        "## Convert to TfLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model(\"Models/ResNet50-STBv1.0_13\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdZquiRGUgVB",
        "outputId": "e44056c1-7f17-49ea-c11c-cd177f2dc51b"
      },
      "outputs": [],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('Models/ResNet50-STBv1.0_13.Lite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaTZcGrqbssG",
        "outputId": "263f3a68-f71e-41e5-a098-f6ba3279d731"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
